# 对话总结：深度学习项目中的内存问题

## 初始问题：创建数据集时进程被杀死
- **用户问题**：运行深度学习项目 (`main.py`) 时，在创建数据集时进程被杀死 (`Killed`)，终端输出如下：
  ```
  /home/natsume/dl_env/bin/python /home/natsume/DeepL/DL2021/Homework/HW2/project2/main.py
  Using GPU :     NVIDIA GeForce RTX 4060 Laptop GPU
  Loading data...
  Killed
  ```
- **分析**：
  - 可能原因：由于使用 `numpy.load` 加载大型数据集 (`train_11.npy`, `test_11.npy`, `train_label_11.npy`) 导致内存不足 (OOM)，该命令会将整个文件加载到内存。
  - 创建数据集时，`train_11.npy` 被加载了两次（分别用于 `train_dataset` 和 `dev_dataset`），导致内存使用量激增。
  - 如果在 WSL (Windows Subsystem for Linux) 上运行，系统内存可能受到限制。

- **提供的解决方案**：
  1. **使用内存映射 (`mmap_mode='r'`)**：
     - 修改 `dataProcess.py`，使用 `numpy.load` 带 `mmap_mode='r'` 参数，按需从磁盘加载数据，减少内存占用。
     - 示例：
       ```python
       self.data = np.load(path, mmap_mode='r')
       self.targets = np.load(inputLabel, mmap_mode='r') if inputLabel else None
       ```
  2. **监控内存使用**：
     - 使用 `watch -n 1 free -m` 实时监控系统内存。
  3. **优化数据集加载**：
     - 通过重构 `main.py`，避免重复加载 `train_11.npy`，仅加载一次数据并在内存中分割。
     - 将批次大小 (`BATCH_SIZE`) 从 32 减小到 16 或 8，以降低内存使用量。
  4. **检查 WSL 内存限制**：
     - 如果使用 WSL，编辑 `~/.wslconfig` 增加内存分配：
       ```bash
       [wsl2]
       memory=8GB
       ```
     - 重启 WSL：`wsl --shutdown`。

## 后续更新：数据集大小和内存监控结果
- **用户更新**：
  - 从 `dataProcess.py` 获取的数据集大小：
    - `train_11.npy`：形状 `(1229932, 429)` (~2.11 GB)。
    - `train_label_11.npy`：形状 `(1229932,)` (~4.92 MB)。
    - `test_11.npy`：形状 `(451552, 429)` (~0.77 GB)。
  - 总内存需求：约 5 GB（由于 `train_11.npy` 被加载两次）。
  - 内存使用 (`watch -n 1 free -m`)：
    - 总内存：7787 MB。
    - 使用内存在创建数据集时峰值接近总内存 (~7000 MB)。
    - 可用内存：初始 ~6242 MB。

- **分析**：
  - `train_11.npy` 被加载两次导致内存使用量激增 (~4.24 GB)。
  - `MyDataset` 中的切片操作创建了额外的内存副本，加剧了问题。
  - 系统内存 (7787 MB) 几乎被完全占用，留给其他分配的内存空间不足。

- **提供的解决方案**：
  1. **避免重复加载**：
     - 修改 `main.py`，仅加载一次 `train_11.npy`，并在内存中分割为 `train_dataset` 和 `dev_dataset`：
       ```python
       train_data = np.load(data_root + "train_11.npy", mmap_mode='r')
       train_labels = np.load(data_root + "train_label_11.npy", mmap_mode='r')
       train_index = np.arange(num_of_data)[::10]
       dev_index = np.setdiff1d(np.arange(num_of_data), train_index)
       train_dataset = dataProcess.MyDataset(train_data[train_index], train_labels[train_index], 'train')
       dev_dataset = dataProcess.MyDataset(train_data[dev_index], train_labels[dev_index], 'dev')
       ```
     - 更新 `MyDataset` 以接受 NumPy 数组而非文件路径。
  2. **减少内存副本**：
     - 在初始化时将数据转换为 `torch.FloatTensor`，避免 `__getitem__` 中的重复转换：
       ```python
       self.data = torch.FloatTensor(data)
       self.targets = torch.FloatTensor(targets) if targets is not None else None
       ```
  3. **增加 WSL 内存**：
     - 为 WSL 分配更多内存 (例如 6 GB) 以应对负载。

## 最终问题：理解 `watch -n 1 free -m` 以及内存/显存限制
- **用户问题**：
  - 使用 `mmap_mode='r'` 后，创建数据集成功，使用内存 (`used`) 达到 ~7000 MB。
  - `watch -n 1 free -m` 监控的是内存还是显存？内存和显存什么时候会“爆”？

- **提供的答案**：
  1. **`watch -n 1 free -m` 监控的内容**：
     - 监控 **系统内存 (RAM)**，而非显存。
     - 输出包括：
       - `Mem`：总内存、使用内存、空闲内存、共享内存、缓冲/缓存、可用内存。
       - `Swap`：交换空间使用情况。
     - 监控显存需使用 `nvidia-smi`：
       ```bash
       watch -n 1 nvidia-smi
       ```
  2. **内存“爆” (OOM) 的时机**：
     - **条件**：可用内存 (`available`) 接近 0，且交换空间耗尽。
     - **原因**：
       - 加载大型数据集 (如 `train_11.npy` ~2.1 GB)。
       - 切片或 Tensor 转换创建内存副本。
     - **预防措施**：
       - 使用 `mmap_mode='r'`。
       - 减小批次大小。
       - 增加交换空间或 WSL 内存分配。
  3. **显存“爆” (CUDA Out of Memory) 的时机**：
     - **条件**：显存使用量接近 GPU 总显存 (例如 RTX 4060 的 8 GB)。
     - **原因**：
       - 将大数据移动到 GPU (`data.to(device)`)。
       - 模型参数、梯度和优化器状态占用显存。
     - **预防措施**：
       - 减小批次大小 (如 `BATCH_SIZE=16`)。
       - 将不必要的 Tensor 移动到 CPU (`loss.detach().cpu()`)。
       - 使用 `torch.cuda.empty_cache()` 释放显存。

- **训练建议**：
  - 使用 `nvidia-smi` 监控训练时的显存。
  - 在 `model_training` 中添加内存监控：
    ```python
    if i % 100 == 0:
        print(f"Batch {i}, GPU memory usage:")
        os.system("nvidia-smi")
    ```
  - 每个 epoch 结束时释放显存：
    ```python
    torch.cuda.empty_cache()
    ```

## 关键要点
- 使用 `mmap_mode='r'` 高效加载大型数据集。
- 避免重复数据加载和不必要的内存副本。
- 训练时监控系统内存 (`free -m`) 和显存 (`nvidia-smi`)。
- 调整批次大小和 WSL 内存分配以防止 OOM 或 CUDA 错误。

**对话日期**：2025年5月24日
