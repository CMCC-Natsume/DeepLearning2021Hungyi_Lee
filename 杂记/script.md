è¿™ä¸ªè„šæœ¬å¯ä»¥åœ¨ä½ æ¯æ¬¡è®­ç»ƒè¾¾åˆ°æ–°é«˜åº¦ï¼ˆå¦‚éªŒè¯é›†å‡†ç¡®ç‡ã€æŸå¤±ã€F1-score ç­‰æŒ‡æ ‡æœ‰æå‡ï¼‰æ—¶è‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š

1. ä¿å­˜è¶…å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€ç½‘ç»œç»“æ„ã€åŠ¨é‡ã€è°ƒåº¦å™¨ç­‰ï¼‰ã€‚
2. ä¿å­˜è®­ç»ƒå›¾ï¼ˆå¦‚ loss/accuracy æ›²çº¿ï¼‰ã€‚
3. å°†æ‰€æœ‰å†…å®¹ä¿å­˜åˆ°ä¸€ä¸ªä»¥æ—¶é—´æˆ³å‘½åçš„æ–°å»ºæ–‡ä»¶å¤¹ä¸­ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ Python è„šæœ¬ç¤ºä¾‹ï¼Œå‡è®¾ä½ ä½¿ç”¨çš„æ˜¯ PyTorchï¼ˆå¦‚æœä½ ä½¿ç”¨å…¶ä»–æ¡†æ¶ï¼Œæˆ‘å¯ä»¥å¸®ä½ æ”¹ï¼‰ï¼š

---

### âœ… `auto_save_checkpoint.py`

```python
import os
import json
import torch
import matplotlib.pyplot as plt
from datetime import datetime


def save_training_snapshot(model, optimizer, scheduler, metrics, plots=None, extra_info=None, save_dir='checkpoints'):
    """
    ä¿å­˜å½“å‰è®­ç»ƒçš„å¿«ç…§ï¼ˆæ¨¡å‹ä¿¡æ¯ + é…ç½® + å›¾è¡¨ï¼‰ã€‚

    Args:
        model: PyTorch æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        metrics: å­—å…¸ï¼ŒåŒ…å«å¦‚ {'val_accuracy': 0.92, 'val_loss': 0.3} ç­‰å…³é”®æŒ‡æ ‡
        plots: å­—å…¸ï¼Œå¦‚ {'loss_curve': <matplotlib Figure å¯¹è±¡>, ...}
        extra_info: é¢å¤–ä¿¡æ¯å­—å…¸ï¼Œä¾‹å¦‚ {'batch_size': 64, 'momentum': 0.9}
        save_dir: æ ¹ç›®å½•ï¼Œé»˜è®¤ 'checkpoints'
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    folder_path = os.path.join(save_dir, f'run_{timestamp}')
    os.makedirs(folder_path, exist_ok=True)

    # ä¿å­˜æ¨¡å‹ç»“æ„å’Œå‚æ•°
    torch.save(model.state_dict(), os.path.join(folder_path, 'model_weights.pth'))

    # ä¿å­˜è®­ç»ƒé…ç½®
    config = {
        'learning_rate': optimizer.param_groups[0]['lr'],
        'momentum': optimizer.param_groups[0].get('momentum', None),
        'scheduler': str(type(scheduler).__name__) if scheduler else None,
        'metrics': metrics
    }

    if extra_info:
        config.update(extra_info)

    with open(os.path.join(folder_path, 'config.json'), 'w') as f:
        json.dump(config, f, indent=4)

    # ä¿å­˜å›¾è¡¨
    if plots:
        for name, fig in plots.items():
            fig_path = os.path.join(folder_path, f'{name}.png')
            fig.savefig(fig_path)
            plt.close(fig)

    print(f"[âœ“] Training snapshot saved to: {folder_path}")
```

---

### ğŸ§ª ä½¿ç”¨ç¤ºä¾‹ï¼š

ä½ å¯ä»¥åœ¨è®­ç»ƒå¾ªç¯ä¸­è¿™æ ·ç”¨å®ƒï¼ˆå‡è®¾ä½ åœ¨éªŒè¯é›†ä¸Šå¾—åˆ°äº†ä¸€ä¸ªæ–°çš„æœ€ä½³åˆ†æ•°ï¼‰ï¼š

```python
if val_accuracy > best_accuracy:
    best_accuracy = val_accuracy
    plots = {
        'loss_curve': plot_loss_curve(loss_history),
        'accuracy_curve': plot_accuracy_curve(acc_history),
    }

    save_training_snapshot(
        model=model,
        optimizer=optimizer,
        scheduler=scheduler,
        metrics={'val_accuracy': val_accuracy, 'val_loss': val_loss},
        plots=plots,
        extra_info={
            'batch_size': 64,
            'network_architecture': str(model),
        }
    )
```

---

### ğŸ“ˆ ç¤ºä¾‹ç»˜å›¾å‡½æ•°ï¼ˆå¯é€‰ï¼‰ï¼š

```python
def plot_loss_curve(losses):
    fig, ax = plt.subplots()
    ax.plot(losses, label='Loss')
    ax.set_title('Loss Curve')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.legend()
    return fig

def plot_accuracy_curve(accuracies):
    fig, ax = plt.subplots()
    ax.plot(accuracies, label='Accuracy')
    ax.set_title('Accuracy Curve')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Accuracy')
    ax.legend()
    return fig
```

---

æ˜¯å¦å¸Œæœ›æˆ‘å¸®ä½ å°†è¿™ä¸ªè„šæœ¬ä¸ä½ çš„è®­ç»ƒä¸»å¾ªç¯è‡ªåŠ¨é›†æˆï¼Ÿå¦‚æœä½ æä¾›ä½ ç›®å‰ä½¿ç”¨çš„è®­ç»ƒä»£ç æ¡†æ¶ï¼ˆæ¯”å¦‚æ˜¯å¦ç”¨ PyTorchã€`Trainer` ç±»ã€`Keras` ç­‰ï¼‰ï¼Œæˆ‘å¯ä»¥å¸®ä½ è¿›ä¸€æ­¥å®šåˆ¶ã€‚
